+++

title = "Self-organizing Probability Neural Network Based Intelligent Non-Intrusive Load Monitoring with Applications to Low-cost Residential Measuring Devices"
date = 2020-07-08T00:00:00
draft = false

# Authors. Comma separated list, e.g. ["Bob Smith", "David Jones"].
authors = ["Zejian Zhou", "Yingmeng Xiang", "Hao Xu", "__**Yishen Wang**__", "Di Shi", "Zhiwei Wang"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference paper
# 2 = Journal article
# 3 = Manuscript
# 4 = Report
# 5 = Book
# 6 = Book section
publication_types = ["2"]

# Publication name and optional abbreviated version.
publication = "*Transactions of the Institute of Measurement and Control*, 2020."
publication_short = "*Transactions of the Institute of Measurement and Control*"

# Abstract and optional shortened version.
abstract = "Non-intrusive load monitoring (NILM) is a critical technique for advanced smart grid management due to the convenience of monitoring and analysing individual appliances' power consumption in a non-intrusive fashion. Inspired by emerging machine learning technologies, many recent non-intrusive load monitoring studies have adopted artificial neural networks (ANN) to disaggregate appliancesâ€™ power from the non-intrusive sensors' measurements. However, back-propagation ANNs have a very limit ability to disaggregate appliances caused by the great training time and uncertainty of convergence, which are critical flaws for low-cost devices. In this paper, a novel self-organizing probabilistic neural network (SPNN)-based non-intrusive load monitoring algorithm has been developed specifically for low-cost residential measuring devices. The proposed SPNN has been designed to estimate the probability density function classifying the different types of appliances. Compared to back-propagation ANNs, the SPNN requires less iterative
synaptic weights update and provides guaranteed convergence. Meanwhile, the novel SPNN has less space complexity when compared with conventional PNNs by the self-organizing mechanism which automatically edits the neuron numbers. These advantages make the algorithm especially favourable to low-cost residential NILM devices. The effectiveness of the proposed algorithm is demonstrated through numerical simulation by using the public REDD dataset. Performance comparisons with well-known benchmark algorithms have also been provided in the experiment section."
abstract_short = ""

# Is this a selected publication? (true/false)
selected = false

# Projects (optional).
# Associate this publication with one or more of your projects.
# Simply enter your project's folder or file name without extension.
# E.g. projects = ["deep-learning"] references
# content/project/deep-learning/index.md.
# Otherwise, set projects = [].
projects = ["2017_load_modeling"]

# Slides (optional).
# Associate this publication with Markdown slides.
# Simply enter your slide deck's filename without extension.
# E.g. slides = "example-slides" references
# content/slides/example-slides.md.
# Otherwise, set slides = "".
slides = ""

# Tags (optional).
# Set tags = [] for no tags, or use the form tags = ["A Tag", "Another Tag"] for one or more tags.
tags = ["Load Modeling"]

# Links (optional).
url_pdf = "https://journals.sagepub.com/doi/abs/10.1177/0142331220950865"
#url_preprint = ""
#url_code = ""
#url_dataset = ""
#url_project = ""
#url_slides = ""
#url_video = ""
#url_poster = ""
#url_source = ""

# Custom links (optional).
# Uncomment line below to enable. For multiple links, use the form [{...}, {...}, {...}].
# url_custom = [{name = "Custom Link", url = "http://example.org"}]
# Digital Object Identifier (DOI)
doi = ""

# Does this page contain LaTeX math? (true/false)
math = false

# Featured image
# To use, add an image named featured.jpg/png to your page's folder.

#[image]  
  # Caption (optional)
  #caption = ""
  
  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  #focal_point = "

+++
